{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.00000000e+00, 0.00000000e+00, 1.07538544e-03, 0.00000000e+00,\n",
       "         0.00000000e+00, 3.74686841e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         2.26894511e-04, 2.36348449e-05, 2.57147112e-03, 3.15369343e-05,\n",
       "         2.93072076e-03, 7.44024916e-03, 1.18174224e-05, 3.74686841e-05,\n",
       "         4.96568091e-03, 3.79668607e-05, 1.60716945e-03, 2.93207225e-05,\n",
       "         3.74686841e-05, 0.00000000e+00, 2.53112405e-05, 5.51873628e-03,\n",
       "         5.22802768e-03, 3.59249642e-03, 2.84832265e-05, 1.88369714e-03,\n",
       "         1.77261337e-04, 3.74686841e-05, 5.90871122e-05, 2.12713604e-05,\n",
       "         3.58364386e-05, 6.40504296e-04, 2.69563726e-05, 4.27248398e-05,\n",
       "         2.12713604e-04, 3.66340095e-04, 6.66502625e-04, 1.43430363e-04,\n",
       "         2.84832265e-05, 0.00000000e+00, 3.94701909e-04, 3.74686841e-05,\n",
       "         3.52159189e-04, 2.95435561e-04, 1.12406052e-04, 1.52392804e-05,\n",
       "         5.79053699e-04, 1.19592315e-03, 3.28524344e-04, 2.14840740e-03,\n",
       "         1.94977690e-05, 1.65443914e-05, 3.32101955e-05, 0.00000000e+00,\n",
       "         1.53153795e-03, 4.01792363e-05, 6.61775656e-05, 1.25264678e-04,\n",
       "         2.53112405e-05, 1.12738210e-03, 1.77261337e-04, 7.66092975e-05,\n",
       "         4.04155847e-04, 1.57880764e-03, 3.56886158e-04, 6.85767618e-05,\n",
       "         1.17228831e-03, 2.60628644e-05, 1.93805728e-04, 8.27219570e-05,\n",
       "         6.51571611e-06, 7.39770644e-04, 3.15369343e-05, 7.49307353e-05,\n",
       "         1.96169212e-04, 7.61964020e-06, 3.74686841e-05, 0.00000000e+00,\n",
       "         5.05785680e-04, 1.27682163e-05, 2.93207225e-05, 1.06356802e-04,\n",
       "         1.68752792e-03, 9.92663484e-05, 7.32680191e-05, 8.98545755e-06,\n",
       "         1.18174224e-04, 4.04155847e-04, 8.98545755e-06, 4.56100128e-05,\n",
       "         1.79709151e-05, 1.52392804e-05, 3.04785608e-05, 3.19205406e-05,\n",
       "         3.19205406e-05, 1.42416133e-05, 3.37483207e-05, 2.84832265e-05,\n",
       "         0.00000000e+00, 1.22433156e-05, 0.00000000e+00, 4.18336754e-04,\n",
       "         2.59983294e-04, 1.63316778e-03, 1.60716945e-04, 7.09045346e-05,\n",
       "         0.00000000e+00, 0.00000000e+00, 3.21906587e-03, 1.66050977e-05,\n",
       "         7.18499284e-04, 6.32781012e-05, 9.45393795e-06, 1.81515609e-03,\n",
       "         6.16869451e-04, 7.49373681e-05, 0.00000000e+00, 5.06224810e-05,\n",
       "         2.12713604e-05, 5.48410211e-05, 1.23798606e-04, 3.15369343e-05,\n",
       "         2.62346778e-04, 3.30887828e-05, 3.15369343e-05, 7.23226253e-04,\n",
       "         7.13772315e-04, 6.18993031e-05, 6.38140811e-05, 1.18174224e-04,\n",
       "         4.27248398e-05, 2.50529356e-04, 3.75794033e-04, 1.05123114e-05,\n",
       "         5.55418854e-04, 1.05123114e-05, 8.48490931e-04, 2.10246229e-05,\n",
       "         3.78157518e-05, 2.52892840e-04, 1.22664845e-03, 4.25427208e-05,\n",
       "         0.00000000e+00, 3.67299468e-05, 0.00000000e+00, 3.15369343e-05,\n",
       "         9.77357417e-06, 1.96169212e-04, 2.41075418e-04, 3.74686841e-05,\n",
       "         8.27219570e-05, 2.84832265e-05, 3.89955380e-05, 1.65443914e-04,\n",
       "         1.66050977e-05, 1.36660049e-04, 6.18993031e-05, 2.10246229e-05,\n",
       "         5.10728650e-05, 9.77357417e-06, 2.55364325e-05, 3.06238657e-04,\n",
       "         6.64203910e-05, 2.84832265e-05, 0.00000000e+00, 1.20537709e-04,\n",
       "         8.98545755e-06, 2.31621480e-04, 2.32270708e-05, 3.78157518e-05,\n",
       "         2.69563726e-05, 6.51571611e-06, 3.25785806e-05, 2.93072076e-04,\n",
       "         6.74966413e-05, 1.08529838e-04, 3.14343437e-04, 1.42416133e-05,\n",
       "         2.51947446e-03, 1.11083771e-04, 1.30314322e-05, 3.74686841e-05,\n",
       "         3.07252983e-05, 3.79668607e-05, 3.74686841e-05, 1.77261337e-04,\n",
       "         3.14343437e-04, 9.77357417e-06, 2.28050064e-05, 2.12713604e-04,\n",
       "         1.95471483e-05, 3.07252983e-05, 9.77357417e-06, 3.54522673e-05,\n",
       "         3.78268366e-02, 5.63902464e-03, 8.31982992e-02, 1.84078506e-03,\n",
       "         3.50008426e-04, 1.24460404e-01, 8.82280499e-02, 3.00747981e-03,\n",
       "         2.56672846e-03, 0.00000000e+00, 2.14282936e-02, 1.98273292e-01,\n",
       "         2.48635615e-02, 5.45753879e-03, 1.29632750e-05, 2.92970016e-03,\n",
       "         1.29632750e-04, 5.77125005e-02, 3.38341479e-02, 6.53478695e-02,\n",
       "         1.68522576e-03, 1.21854785e-03, 2.96858998e-03, 2.86747644e-02,\n",
       "         1.29632750e-05, 5.45105716e-02, 5.61439442e-02, 1.77726501e-02,\n",
       "         2.73914002e-02, 2.25301720e-02, 1.37410715e-02, 5.40568569e-03,\n",
       "         5.48346534e-03, 3.75934976e-04, 4.95197107e-03, 1.41105249e-01],\n",
       "        [0.00000000e+00, 0.00000000e+00, 6.39233105e-04, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         3.99520691e-04, 1.62124338e-05, 2.66347127e-03, 1.54520782e-05,\n",
       "         2.41217855e-03, 5.90016788e-03, 1.62124338e-05, 0.00000000e+00,\n",
       "         5.06059542e-03, 2.48033791e-05, 1.43711646e-03, 1.91549415e-05,\n",
       "         0.00000000e+00, 0.00000000e+00, 3.72050686e-05, 4.85562393e-03,\n",
       "         5.87469120e-03, 3.52273027e-03, 0.00000000e+00, 2.12846096e-03,\n",
       "         1.45911904e-04, 0.00000000e+00, 4.16891156e-05, 3.93730536e-05,\n",
       "         1.59624512e-05, 6.40391136e-04, 3.08180859e-05, 6.97793007e-06,\n",
       "         2.75611375e-04, 3.80992195e-04, 8.47678683e-04, 1.36418585e-04,\n",
       "         0.00000000e+00, 0.00000000e+00, 7.49246049e-04, 0.00000000e+00,\n",
       "         4.15733125e-04, 3.96046598e-04, 0.00000000e+00, 1.12001321e-05,\n",
       "         5.29220162e-04, 1.86906201e-03, 3.39303080e-04, 2.34153866e-03,\n",
       "         0.00000000e+00, 2.66347127e-05, 8.13596106e-06, 0.00000000e+00,\n",
       "         1.33984185e-03, 2.89507747e-05, 3.47409296e-05, 6.83238283e-05,\n",
       "         2.27364308e-05, 1.48691179e-03, 1.84126927e-04, 3.12800659e-05,\n",
       "         4.75950736e-04, 1.62819157e-03, 2.94139871e-04, 2.98670189e-05,\n",
       "         1.32478745e-03, 3.83098829e-05, 1.62124338e-04, 9.84326340e-05,\n",
       "         1.59624512e-06, 5.92911866e-04, 5.15069274e-06, 6.54460500e-05,\n",
       "         2.18867857e-04, 7.46675472e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "         4.85214984e-04, 9.38401976e-06, 6.86385403e-05, 8.56942931e-05,\n",
       "         1.89569673e-03, 4.97953325e-05, 6.83238283e-05, 2.64155022e-05,\n",
       "         1.45911904e-04, 4.46999961e-04, 1.76103348e-05, 2.71361671e-05,\n",
       "         1.32077511e-05, 1.12001321e-05, 4.48005283e-05, 0.00000000e+00,\n",
       "         2.50240527e-05, 0.00000000e+00, 2.89372756e-05, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.34261621e-04,\n",
       "         3.14984429e-04, 1.82853093e-03, 1.88759051e-04, 7.75880762e-05,\n",
       "         0.00000000e+00, 0.00000000e+00, 2.30795576e-03, 0.00000000e+00,\n",
       "         9.17160543e-04, 5.16737064e-05, 5.79015494e-06, 2.17594023e-03,\n",
       "         5.30378193e-04, 0.00000000e+00, 0.00000000e+00, 8.06109820e-05,\n",
       "         1.38963719e-05, 4.34059134e-05, 1.40469571e-04, 2.57534637e-05,\n",
       "         3.02246088e-04, 4.51632085e-05, 2.57534637e-05, 6.69341911e-04,\n",
       "         8.51152776e-04, 2.55399220e-05, 5.21113945e-05, 1.27383409e-04,\n",
       "         0.00000000e+00, 2.43186507e-04, 4.08784939e-04, 0.00000000e+00,\n",
       "         5.36168347e-04, 0.00000000e+00, 1.29931077e-03, 4.37808883e-05,\n",
       "         6.02176114e-05, 1.84126927e-04, 1.27846621e-03, 3.70569916e-05,\n",
       "         0.00000000e+00, 5.99882882e-06, 0.00000000e+00, 1.54520782e-05,\n",
       "         1.43662061e-05, 1.74862679e-04, 3.04562150e-04, 0.00000000e+00,\n",
       "         6.48497353e-05, 0.00000000e+00, 0.00000000e+00, 1.62124338e-04,\n",
       "         0.00000000e+00, 1.00438508e-04, 1.21314629e-04, 3.34795028e-05,\n",
       "         2.50240527e-05, 1.59624512e-05, 2.18960461e-05, 1.43662061e-04,\n",
       "         8.13596106e-06, 0.00000000e+00, 0.00000000e+00, 6.60077663e-05,\n",
       "         0.00000000e+00, 1.91075113e-04, 0.00000000e+00, 2.66347127e-05,\n",
       "         4.40258370e-06, 1.75586963e-05, 1.59624512e-06, 1.81810865e-04,\n",
       "         4.13389651e-05, 0.00000000e+00, 3.65937792e-04, 6.97793007e-06,\n",
       "         2.46660600e-03, 1.08854913e-04, 2.87324122e-05, 0.00000000e+00,\n",
       "         1.15803099e-05, 5.58076029e-05, 0.00000000e+00, 2.29290136e-04,\n",
       "         2.98771995e-04, 2.55399220e-05, 1.27699610e-05, 1.96865268e-04,\n",
       "         1.27699610e-05, 3.70569916e-05, 3.03286573e-05, 4.63212395e-05,\n",
       "         3.83635775e-02, 4.45881314e-03, 7.61745670e-02, 2.54698586e-03,\n",
       "         6.16103810e-04, 1.11895885e-01, 9.69633069e-02, 3.09957381e-03,\n",
       "         2.15953913e-03, 0.00000000e+00, 2.62320488e-02, 1.91087455e-01,\n",
       "         2.17160714e-02, 9.29236984e-03, 0.00000000e+00, 3.07416747e-03,\n",
       "         1.14328542e-04, 6.07465654e-02, 2.79406254e-02, 6.79429119e-02,\n",
       "         1.80385033e-03, 1.30842665e-03, 2.57239220e-03, 3.22215941e-02,\n",
       "         0.00000000e+00, 6.38397876e-02, 5.28007317e-02, 1.77463304e-02,\n",
       "         2.70641066e-02, 2.43519795e-02, 1.67427798e-02, 4.64300913e-03,\n",
       "         5.33533197e-03, 2.41360256e-04, 4.85896304e-03, 1.07957902e-01]]),\n",
       " array([28., 40.]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "import numpy\n",
    "from nltk import word_tokenize\n",
    "from numpy import array\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "\n",
    "def clean_and_tokenize_file(file_name):\n",
    "    file = open(file_name)\n",
    "    raw_text= file.read()\n",
    "    words = raw_text.lower().split()\n",
    "    return words\n",
    "\n",
    "def clean_and_tokenize_corpus(directories):\n",
    "    file_list = []\n",
    "    for directory in directories:\n",
    "        for file_name in os.listdir(directory):\n",
    "            if file_name != '.DS_Store':\n",
    "                file = open(directory + file_name)\n",
    "                raw_text = file.read()\n",
    "                tokens = raw_text.split()\n",
    "                file_list.append(tokens)\n",
    "                file.close()\n",
    "    return file_list\n",
    "\n",
    "def count_total_vocab(file_wordfreqs):\n",
    "    vocab = {}\n",
    "    for words in file_wordfreqs:\n",
    "        for word in words:\n",
    "            if word in vocab:\n",
    "                vocab[word] += 1\n",
    "            else:\n",
    "                vocab[word] = 1\n",
    "    return vocab\n",
    "\n",
    "def get_corpus_vocab(corpus, unknown_threshold):\n",
    "    initial_dict = count_total_vocab(corpus)\n",
    "    filtered_dict = [word for word, size in initial_dict.items()][:unknown_threshold]\n",
    "    return filtered_dict\n",
    "\n",
    "def get_idf_dict(vocab, corpus):\n",
    "    idf_dict = {}\n",
    "    num_docs = len(corpus)\n",
    "    for word in vocab:\n",
    "        df_count = 0\n",
    "        for doc in corpus:\n",
    "            if word in doc:\n",
    "                df_count += 1\n",
    "        idf_dict[word] = math.log(num_docs / df_count)\n",
    "    return idf_dict\n",
    "\n",
    "def feature_vector(novel, vocab, idf_dict, pos_tags):\n",
    "    tokenized_novel = clean_and_tokenize_file(novel)\n",
    "    word_vector = tf_idf(vocab, tokenized_novel, idf_dict)\n",
    "    tagged_tokens = nltk.pos_tag(tokenized_novel)\n",
    "    tags = [tag for (word, tag) in tagged_tokens]\n",
    "    num_tokens = len(tokenized_novel)\n",
    "    pos_vector = [tags.count(pos_tag) / num_tokens for pos_tag in pos_tags]\n",
    "    word_vector = word_vector + pos_vector\n",
    "    \n",
    "    # gets ratio of unique words to total # of words\n",
    "    novel_vocab = count_total_vocab([tokenized_novel])\n",
    "    vocab_size = len(novel_vocab) / len(tokenized_novel)\n",
    "    word_vector.append(vocab_size)\n",
    "    \n",
    "    return word_vector\n",
    "\n",
    "def tf_idf(vocab, document, idf_dict):\n",
    "    counts = Counter(document)\n",
    "    doc_len = len(document)\n",
    "    doc_num = len(corpus)\n",
    "    tf_idfs = []\n",
    "    for word in vocab:\n",
    "        doc_counter = 0\n",
    "        tf = counts[word] / len(document)\n",
    "        idf = idf_dict[word]\n",
    "        tf_idfs.append(tf*idf)\n",
    "    return tf_idfs\n",
    "\n",
    "def create_vector_arrays(training_data, corpus_dict, vocab, idf_dict, pos_tags):\n",
    "    len_feature_vector = len(vocab) + len(pos_tags) + 1\n",
    "    print(len_feature_vector)\n",
    "    vector_array = numpy.zeros((len(training_data), len_feature_vector))\n",
    "    results_array = numpy.zeros(len(training_data))\n",
    "    index = 0\n",
    "    for data, age in training_data.items():\n",
    "        results_array[index] = age\n",
    "        vector_array[index] = feature_vector(corpus_dict + data, vocab, idf_dict, pos_tags)\n",
    "        index += 1\n",
    "    return (vector_array, results_array)\n",
    "    \n",
    "    \n",
    "training_data = {'121-0.txt': 28, '158-0.txt':40}\n",
    "corpus = clean_and_tokenize_corpus(['data/JaneAusten/', 'data/CarrollLewis/', 'data/CharlesDickens/'])\n",
    "vocab = get_corpus_vocab(corpus, 200)\n",
    "idf_dict = get_idf_dict(vocab, corpus)\n",
    "corpus_dict = 'data/JaneAusten/'    \n",
    "\n",
    "tagset = ['CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNS', 'NNP', 'NNPS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB']\n",
    "\n",
    "create_vector_arrays(training_data, corpus_dict, vocab, idf_dict, tagset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from torch import tensor, Size\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch import functional\n",
    "from torch import from_numpy\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "input_array = array(features_vector_array[0], dtype='float32')\n",
    "input_vector = from_numpy(input_array)\n",
    "\n",
    "output_array = array(features_vector_array[1], dtype='float32')\n",
    "target_vector = from_numpy(output_array)\n",
    "\n",
    "input_and_target = TensorDataset(input_vector, target_vector)\n",
    "\n",
    "predict_array = array(test_vector, dtype='float32')\n",
    "predict_vector = from_numpy(predict_array)\n",
    "\n",
    "dickens_predict_array = array(dickens_test_array, dtype='float32')\n",
    "dickens_predict_vector = from_numpy(dickens_predict_array)\n",
    "\n",
    "linear_model = nn.Linear(115, 1)\n",
    "loss_func = nn.functional.mse_loss \n",
    "optimize = optim.SGD(linear_model.parameters(), lr=0.001)\n",
    "loss = loss_func(linear_model(input_vector), target_vector)\n",
    "\n",
    "def train(num_epochs, model, loss_func, optimizer):\n",
    "    for epoch in range(num_epochs):\n",
    "        for xb,yb in input_and_target:\n",
    "            \n",
    "            # Predictions\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "            \n",
    "            # Stochastic radient descent\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "    print(loss)\n",
    "\n",
    "train(500, linear_model, loss_func, optimize)\n",
    "\n",
    "pred = linear_model(predict_vector)\n",
    "print(pred)\n",
    "\n",
    "def goodness(predicted, actual, range_size):\n",
    "    return float((predicted - actual)) / float(range_size)\n",
    "\n",
    "print(\"Jane Austen\")\n",
    "print(\"Age predicted for Mansfield Park: %s\" % pred)\n",
    "print(\"Goodness Metric: %s\\n\" % abs(goodness(pred, 39, 15)))\n",
    "\n",
    "pred = linear_model(dickens_predict_vector)\n",
    "print(\"Charles Dickens\")\n",
    "print(\"Age predicted for Oliver Twist: %s\" % pred)\n",
    "print(\"Goodness Metric: %s\" % abs(goodness(pred, 25, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
