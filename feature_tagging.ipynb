{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "def clean_and_tokenize_corpus(directories):\n",
    "    word_file_list = []\n",
    "    sent_file_list = []\n",
    "    for directory in directories:\n",
    "        for file_name in os.listdir(directory):\n",
    "            if file_name != '.DS_Store':\n",
    "                file = open(directory + file_name)\n",
    "                raw_text = file.read().lower()\n",
    "                tokens = nltk.word_tokenize(raw_text)\n",
    "                no_punct_tokens = [x for x in tokens if re.match('\\w+', x)]\n",
    "                file_list.append(no_punct_tokens)\n",
    "                file.close()\n",
    "    return file_list\n",
    "\n",
    "corpus = clean_and_tokenize_corpus(['data/JaneAusten/', 'data/CarrollLewis/', 'data/CharlesDickens/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "\n",
    "def train_word2vec(corpus):\n",
    "    model = Word2Vec(corpus, size=100)\n",
    "    model.train(corpus, total_examples=len(corpus), epochs=50)\n",
    "    return model\n",
    "\n",
    "word2vec = train_word2vec(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:62: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:63: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:73: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:74: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 1.14299160e-03,  5.34683929e-04,  9.51302116e-04,\n",
       "          5.40968941e-06,  1.78155942e-05,  5.90456348e-05,\n",
       "          1.65217869e-05,  6.36671459e-03,  3.17497667e-05,\n",
       "          4.48413777e-03,  5.84800459e-04,  2.02276871e-04,\n",
       "          3.20438608e-05,  2.22905106e-03,  4.00850869e-05,\n",
       "          2.52745952e-03,  3.20438608e-05,  4.61832143e-03,\n",
       "          2.48454442e-05,  1.44798196e-03,  2.48454442e-05,\n",
       "          7.24073304e-05,  2.16696608e-03,  2.50225933e-05,\n",
       "          4.71645576e-03,  3.08021612e-03,  4.82715536e-05,\n",
       "          1.52208339e-04,  1.65217869e-05,  7.61041693e-05,\n",
       "          3.20438608e-05,  3.31272589e-05,  6.90945748e-04,\n",
       "          1.78732809e-05,  5.18729738e-05,  1.86254941e-04,\n",
       "          3.16433125e-04,  5.78792235e-04,  9.93817766e-05,\n",
       "          1.60219304e-05,  1.60619852e-03,  3.44471503e-04,\n",
       "          3.00411195e-04,  2.76378299e-04,  9.52493000e-05,\n",
       "          1.08193788e-05,  5.32729185e-04,  1.08949127e-03,\n",
       "          3.24444090e-04,  2.07684273e-03,  1.40706297e-05,\n",
       "          1.60219304e-05,  3.21719057e-05,  1.17961462e-03,\n",
       "          1.32581474e-03,  6.60904628e-05,  1.10150771e-04,\n",
       "          2.85972495e-05,  9.83345977e-04,  2.28312508e-04,\n",
       "          9.19647200e-05,  3.42468762e-04,  1.36987505e-03,\n",
       "          3.06419419e-04,  7.74796781e-05,  1.06545837e-03,\n",
       "          2.76060491e-05,  1.76241234e-04,  7.20986867e-05,\n",
       "          4.00548260e-06,  6.64910111e-04,  1.93699195e-05,\n",
       "          5.60767563e-05,  1.80246717e-04,  5.40968941e-06,\n",
       "          2.41357768e-05,  4.56625016e-04,  1.08193788e-05,\n",
       "          2.20301543e-05,  1.24169960e-04,  1.04142547e-04,\n",
       "          7.20986867e-05,  1.10150771e-04,  3.94540036e-04,\n",
       "          1.40191891e-05,  3.86484687e-05,  5.52120981e-06,\n",
       "          2.14479371e-05,  3.86484687e-05,  2.00274130e-05,\n",
       "          2.70484470e-05,  8.90779709e-06,  2.48454442e-05,\n",
       "          2.76060491e-06,  1.42524753e-04,  1.03745948e-05,\n",
       "          4.10561966e-04,  2.48339921e-04,  1.40792713e-03,\n",
       "          1.52208339e-04,  7.00959454e-05,  6.79611415e-03,\n",
       "          4.57196640e-03,  3.11826820e-03,  1.29132797e-05,\n",
       "          6.18847061e-04,  6.07691551e-05,  3.13933026e-06,\n",
       "          1.59217933e-03,  5.26720961e-04,  2.95483224e-04,\n",
       "          7.14931237e-05,  8.61178758e-05,  6.07333079e-05,\n",
       "          1.76241234e-04,  1.29748431e-04,  2.66364593e-04,\n",
       "          3.80520847e-05,  4.45389855e-05,  6.22852544e-04,\n",
       "          6.86940265e-04,  5.24514932e-05,  5.40740150e-05,\n",
       "          2.28419696e-05,  2.22304284e-04,  3.30452314e-04,\n",
       "          5.40968941e-06,  4.90671618e-04,  5.60767563e-05,\n",
       "          7.57036211e-04,  1.10424196e-05,  1.74238493e-04,\n",
       "          2.40328956e-04,  1.05143918e-03,  4.80657911e-05,\n",
       "          1.52279797e-05,  6.62545178e-05,  2.28419696e-05,\n",
       "          2.40328956e-05,  1.72235752e-04,  2.30315249e-04,\n",
       "          1.96818783e-05,  8.41151345e-05,  2.41357768e-05,\n",
       "          3.30435739e-05,  1.78243976e-04,  3.22831992e-05,\n",
       "          7.00959454e-05,  1.10424196e-05,  4.28958742e-05,\n",
       "          3.60493434e-05,  2.50225933e-05,  1.80246717e-05,\n",
       "          1.52279797e-05,  2.19700720e-03,  1.08148030e-04,\n",
       "          1.29132797e-05,  2.86392006e-04,  3.40466021e-05,\n",
       "          1.93699195e-05,  5.52120981e-06,  3.58878638e-05,\n",
       "          2.56350886e-04,  1.22167219e-04,  1.06893565e-04,\n",
       "          2.76378299e-04,  7.45363325e-05,  9.81343236e-05,\n",
       "          2.48454442e-05,  8.19121191e-04,  2.60356369e-05,\n",
       "          4.60630499e-05,  1.72235752e-04,  4.34594862e-04,\n",
       "          8.28181472e-06,  2.20848393e-05,  1.20164478e-05,\n",
       "          2.60356369e-05,  1.10424196e-05,  2.74375558e-04,\n",
       "          1.65636294e-04,  7.41014280e-05,  4.38600344e-04,\n",
       "          1.74238493e-04,  5.20712737e-05,  7.72969374e-05,\n",
       "          1.02139806e-04,  4.06556483e-04,  1.33616956e-05,\n",
       "          3.57465618e-06,  1.29132797e-05,  1.10150771e-04,\n",
       "          2.76060491e-05,  1.90498600e-04,  4.60630499e-05,\n",
       "          3.80520847e-05,  7.65047176e-04,  2.96405712e-04,\n",
       "          5.52120981e-06,  3.57465618e-06,  3.62823498e-02,\n",
       "          5.31657806e-03,  7.32347643e-02,  1.73557713e-03,\n",
       "          5.93171932e-04,  1.07243288e-01,  6.81598489e-02,\n",
       "          2.57041171e-03,  2.38367239e-03,  0.00000000e+00,\n",
       "          1.94318731e-02,  1.48402830e-01,  2.74946175e-02,\n",
       "          9.88619887e-03,  1.09846654e-05,  2.20791775e-03,\n",
       "          4.69045213e-03,  6.00202118e-02,  3.01638912e-02,\n",
       "          6.66769190e-02,  1.76853113e-03,  9.99604552e-04,\n",
       "          2.79010501e-03,  2.45946658e-02,  1.20831319e-03,\n",
       "          4.71901226e-02,  5.06393075e-02,  1.60925348e-02,\n",
       "          2.57700250e-02,  1.79709126e-02,  1.02267235e-02,\n",
       "          4.82226811e-03,  4.81128345e-03,  3.18555297e-04,\n",
       "          4.77832945e-03, -1.32556781e-01,  2.17231348e-01,\n",
       "          1.84277207e-01,  3.36169630e-01,  6.49212748e-02,\n",
       "         -2.39035934e-01,  7.51488358e-02, -1.66500900e-02,\n",
       "          1.35290965e-01,  4.86065477e-01, -6.63615903e-03,\n",
       "         -2.41974607e-01, -1.60969183e-01, -1.90267092e-05,\n",
       "          6.98189735e-02, -2.49405175e-01,  2.96697706e-01,\n",
       "         -7.74384260e-01, -4.10978973e-01, -2.96136230e-01,\n",
       "         -9.77301151e-02,  1.36262894e-01, -1.77487537e-01,\n",
       "          1.63521245e-01, -2.59021044e-01,  3.20754945e-02,\n",
       "          1.64475530e-01,  2.20750093e-01, -2.28634566e-01,\n",
       "          9.53251198e-02, -2.26339325e-02,  1.49055034e-01,\n",
       "          4.09704484e-02,  4.11656797e-01,  2.72938088e-02,\n",
       "          8.71691555e-02,  2.54521132e-01, -2.16689378e-01,\n",
       "          1.69812009e-01, -2.46660456e-01, -1.58865154e-01,\n",
       "          1.99976593e-01, -6.36720136e-02,  7.73528144e-02,\n",
       "          2.00852770e-02,  1.07963264e-01,  3.29553150e-02,\n",
       "         -2.54832357e-01,  1.45339638e-01,  3.51598449e-02,\n",
       "         -1.44909889e-01, -4.45749789e-01, -5.69175184e-03,\n",
       "         -5.31971045e-02, -2.12327570e-01, -7.61411414e-02,\n",
       "         -2.45012511e-02,  8.62911716e-02, -2.63919353e-01,\n",
       "          5.22768982e-02,  2.84782350e-01, -1.08419038e-01,\n",
       "         -4.56901103e-01, -1.00041486e-01,  2.65571803e-01,\n",
       "         -1.11842446e-01,  8.66747200e-02, -1.90290228e-01,\n",
       "          7.14336149e-03, -8.93625617e-02,  4.55207229e-01,\n",
       "         -5.03757261e-02,  2.52066284e-01,  3.11184376e-01,\n",
       "         -1.85177311e-01,  8.85437503e-02, -1.11333646e-01,\n",
       "          2.83868283e-01, -1.42267272e-01, -1.15383446e-01,\n",
       "         -1.27303183e-01,  1.38461426e-01, -2.58312136e-01,\n",
       "         -8.47303197e-02, -3.48863244e-01,  2.10373074e-01,\n",
       "          1.13302544e-01,  2.07671508e-01, -2.77992878e-02,\n",
       "          2.25938261e-01,  1.52071295e-02,  1.66065171e-01,\n",
       "         -3.04848731e-01,  8.75068307e-02,  1.92981780e-01,\n",
       "         -1.78283036e-01, -2.87000656e-01, -9.89598259e-02,\n",
       "         -2.63190359e-01,  1.51021972e-01,  7.19385738e-02,\n",
       "          3.04666877e-01],\n",
       "        [ 0.00000000e+00,  1.54683474e-04,  5.43720535e-04,\n",
       "          7.67947140e-04,  4.25767848e-06,  0.00000000e+00,\n",
       "          0.00000000e+00,  4.97580870e-03,  0.00000000e+00,\n",
       "          4.95570636e-03,  5.01601339e-04,  3.42697098e-04,\n",
       "          1.81878348e-05,  2.29358169e-03,  2.55460709e-05,\n",
       "          2.07724218e-03,  2.39313616e-05,  4.66661551e-03,\n",
       "          1.97923818e-05,  1.28272098e-03,  1.84728897e-05,\n",
       "          0.00000000e+00,  2.35101696e-03,  3.41717184e-05,\n",
       "          4.09609185e-03,  2.99142020e-03,  0.00000000e+00,\n",
       "          1.25400335e-04,  0.00000000e+00,  5.16917410e-05,\n",
       "          4.97772321e-05,  1.71533976e-05,  7.02624776e-04,\n",
       "          7.17606087e-05,  4.95876684e-06,  2.38356361e-04,\n",
       "          3.41739843e-04,  7.22727120e-04,  9.36839408e-05,\n",
       "          4.78627232e-06,  1.72401529e-03,  6.26044419e-04,\n",
       "          3.53226897e-04,  3.64713950e-04,  0.00000000e+00,\n",
       "          1.55140836e-05,  5.11173883e-04,  1.72880156e-03,\n",
       "          3.35039062e-04,  2.17679665e-03,  0.00000000e+00,\n",
       "          2.29741071e-05,  4.27146480e-05,  1.37748917e-03,\n",
       "          1.16210692e-03,  3.63756696e-05,  6.12642856e-05,\n",
       "          2.05030311e-05,  1.25878962e-03,  2.05809710e-04,\n",
       "          4.39565703e-05,  3.98217857e-04,  1.37461741e-03,\n",
       "          2.49843415e-04,  3.70331244e-05,  1.18508103e-03,\n",
       "          4.61822243e-05,  1.50288951e-04,  9.09391740e-05,\n",
       "          1.91450893e-06,  5.31276227e-04,  3.08609370e-06,\n",
       "          5.26489955e-05,  1.90493638e-04,  5.17136121e-06,\n",
       "          0.00000000e+00,  4.32679017e-04,  7.75704182e-06,\n",
       "          4.97772321e-05,  1.18699553e-04,  5.16917410e-05,\n",
       "          6.22215401e-05,  1.32101116e-04,  4.40337053e-04,\n",
       "          1.14870536e-05,  2.24313661e-05,  2.24313661e-05,\n",
       "          1.87944451e-05,  6.86135904e-05,  5.74352678e-06,\n",
       "          2.32711254e-05,  0.00000000e+00,  2.24313661e-05,\n",
       "          1.31949212e-06,  1.19214997e-04,  0.00000000e+00,\n",
       "          4.25978236e-04,  2.81432812e-04,  1.55266674e-03,\n",
       "          1.81878348e-04,  6.89223213e-05,  6.72536842e-06,\n",
       "          0.00000000e+00,  2.31751306e-03,  3.08609370e-06,\n",
       "          7.80162387e-04,  5.98005073e-05,  1.50051227e-06,\n",
       "          1.88004777e-03,  4.43208816e-04,  6.72536842e-06,\n",
       "          1.09349499e-04,  6.60505579e-05,  5.54186692e-05,\n",
       "          1.88579129e-04,  8.70864801e-05,  2.85261830e-04,\n",
       "          6.12642856e-05,  5.10921418e-05,  5.73395423e-04,\n",
       "          7.97392968e-04,  2.37508582e-05,  4.40337053e-05,\n",
       "          3.63927472e-06,  2.04852455e-04,  3.42697098e-04,\n",
       "          7.75704182e-06,  4.72883705e-04,  1.27314844e-04,\n",
       "          1.14870536e-03,  2.63898425e-05,  2.20168526e-04,\n",
       "          1.69434040e-04,  1.09031283e-03,  5.07344865e-05,\n",
       "          7.27854944e-06,  5.01407007e-05,  4.00320219e-05,\n",
       "          1.62733259e-05,  1.69434040e-04,  2.94834375e-04,\n",
       "          0.00000000e+00,  7.84948660e-05,  0.00000000e+00,\n",
       "          0.00000000e+00,  1.73263058e-04,  2.16026559e-05,\n",
       "          1.16785044e-04,  2.63898425e-05,  3.58803044e-05,\n",
       "          5.36062499e-05,  5.80919213e-05,  2.87176339e-06,\n",
       "          2.54749230e-05,  2.23614643e-03,  6.12642856e-05,\n",
       "          3.08609370e-06,  2.26869308e-04,  2.58458705e-05,\n",
       "          3.08609370e-06,  1.45144134e-05,  7.91695274e-06,\n",
       "          1.56032477e-04,  7.27513392e-05,  0.00000000e+00,\n",
       "          3.11107700e-04,  2.63898425e-05,  1.10084263e-04,\n",
       "          3.29873031e-05,  6.57633816e-04,  1.05297991e-05,\n",
       "          5.36062499e-05,  2.10595982e-04,  3.99175111e-04,\n",
       "          2.24313661e-05,  1.71533976e-05,  7.65803570e-06,\n",
       "          3.25466517e-05,  4.48627322e-05,  2.60373214e-04,\n",
       "          9.89619092e-05,  2.96748884e-05,  5.30318973e-04,\n",
       "          2.27826562e-04,  4.11619419e-05,  5.54186692e-05,\n",
       "          8.23238838e-05,  5.22660937e-04,  0.00000000e+00,\n",
       "          3.41717184e-06,  0.00000000e+00,  1.20614062e-04,\n",
       "          1.18754291e-05,  0.00000000e+00,  8.23238838e-05,\n",
       "          8.80674106e-05,  5.16917410e-04,  6.12642856e-05,\n",
       "          7.91695274e-06,  2.05030311e-05,  3.73563369e-02,\n",
       "          4.22654269e-03,  6.66271139e-02,  2.42041761e-03,\n",
       "          1.02907126e-03,  9.49895780e-02,  7.00976043e-02,\n",
       "          2.88244961e-03,  2.22615416e-03,  0.00000000e+00,\n",
       "          2.33378661e-02,  1.40184708e-01,  2.29283378e-02,\n",
       "          1.28738915e-02,  1.05007272e-05,  2.32591107e-03,\n",
       "          4.39455432e-03,  6.43064532e-02,  2.48132183e-02,\n",
       "          6.85644981e-02,  1.83762726e-03,  1.06582381e-03,\n",
       "          2.37841471e-03,  2.71811323e-02,  1.24958653e-03,\n",
       "          5.59006211e-02,  4.74580365e-02,  1.61658695e-02,\n",
       "          2.48972241e-02,  1.88120527e-02,  1.28581404e-02,\n",
       "          4.07428214e-03,  4.75157905e-03,  2.04764180e-04,\n",
       "          4.68857468e-03, -9.58374664e-02,  2.24856228e-01,\n",
       "          1.51751608e-01,  3.28047782e-01, -2.77979914e-02,\n",
       "         -2.87524849e-01,  3.79914790e-02, -1.85536910e-02,\n",
       "          6.15890138e-02,  4.61489916e-01,  1.23655703e-02,\n",
       "         -1.96792319e-01, -2.07040802e-01, -1.99402943e-02,\n",
       "          7.95085132e-02, -3.37621987e-01,  3.30631733e-01,\n",
       "         -8.19008470e-01, -4.23821747e-01, -3.52300435e-01,\n",
       "         -5.82881756e-02,  1.35780960e-01, -1.56137183e-01,\n",
       "          3.17129850e-01, -2.19598785e-01,  3.10498495e-02,\n",
       "          2.37196848e-01,  3.36955756e-01, -2.27940947e-01,\n",
       "          1.55622497e-01, -6.28559068e-02,  1.94879338e-01,\n",
       "          3.38234752e-03,  4.46711779e-01,  8.85864571e-02,\n",
       "          1.52653351e-01,  3.10893893e-01, -2.61038184e-01,\n",
       "          1.21274143e-01, -2.64649451e-01, -1.33160979e-01,\n",
       "          1.44698262e-01, -7.88517445e-02,  5.80059029e-02,\n",
       "         -9.28742287e-04,  9.76299495e-02,  4.35080044e-02,\n",
       "         -2.21980214e-01,  1.08157411e-01,  2.54333559e-02,\n",
       "         -1.99512348e-01, -4.70786572e-01,  2.37091258e-02,\n",
       "         -3.34516242e-02, -3.01824749e-01, -1.29351407e-01,\n",
       "          2.88234595e-02,  2.71457271e-03, -2.57047027e-01,\n",
       "          8.49479958e-02,  3.37662011e-01, -1.21183366e-01,\n",
       "         -3.87905389e-01, -5.81806712e-02,  2.31392354e-01,\n",
       "         -2.68810123e-01,  1.38996765e-01, -2.10231498e-01,\n",
       "         -2.37481613e-02, -8.81857798e-02,  4.84086782e-01,\n",
       "          1.55855957e-02,  3.22005332e-01,  2.99659282e-01,\n",
       "         -1.66507229e-01,  1.03256658e-01, -8.87217969e-02,\n",
       "          2.06775457e-01, -2.44617879e-01, -7.76941702e-02,\n",
       "         -1.05323695e-01,  1.63695753e-01, -2.85318375e-01,\n",
       "         -3.34758721e-02, -4.20120656e-01,  2.00657263e-01,\n",
       "          1.38211712e-01,  2.47495607e-01,  3.40925492e-02,\n",
       "          2.71434009e-01, -1.55055020e-02,  2.09326327e-01,\n",
       "         -2.34414056e-01,  1.59164041e-01,  1.99512586e-01,\n",
       "         -1.66262165e-01, -3.40601385e-01, -1.38944879e-01,\n",
       "         -2.77368873e-01,  1.53573111e-01,  4.40768023e-02,\n",
       "          3.27716202e-01]]), array([28., 40.]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "import numpy\n",
    "from nltk import word_tokenize\n",
    "from numpy import array\n",
    "from collections import Counter\n",
    "import math\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def clean_and_tokenize_file(file_name):\n",
    "    file = open(file_name)\n",
    "    raw_text = file.read().lower()\n",
    "    tokens = nltk.word_tokenize(raw_text)\n",
    "    sentences = nltk.sent_tokenize(raw_text)\n",
    "    sentence_list = []\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        sentence_list.append([x for x in words if re.match('\\w+', x)])\n",
    "    return (tokens, sentence_list)\n",
    "\n",
    "def count_total_vocab(file_wordfreqs):\n",
    "    vocab = {}\n",
    "    for words in file_wordfreqs:\n",
    "        for word in words:\n",
    "            if word in vocab:\n",
    "                vocab[word] += 1\n",
    "            else:\n",
    "                vocab[word] = 1\n",
    "    return vocab\n",
    "\n",
    "def get_corpus_vocab(corpus, unknown_threshold):\n",
    "    initial_dict = count_total_vocab(corpus)\n",
    "    filtered_dict = [word for word, size in initial_dict.items()][:unknown_threshold]\n",
    "    return filtered_dict\n",
    "\n",
    "def get_idf_dict(vocab, corpus):\n",
    "    idf_dict = {}\n",
    "    num_docs = len(corpus)\n",
    "    for word in vocab:\n",
    "        df_count = 0\n",
    "        for doc in corpus:\n",
    "            if word in doc:\n",
    "                df_count += 1\n",
    "        idf_dict[word] = math.log(num_docs / df_count)\n",
    "    return idf_dict\n",
    "\n",
    "def tf_idf(vocab, document, idf_dict):\n",
    "    counts = Counter(document)\n",
    "    doc_len = len(document)\n",
    "    doc_num = len(corpus)\n",
    "    tf_idfs = []\n",
    "    for word in vocab:\n",
    "        doc_counter = 0\n",
    "        tf = counts[word] / len(document)\n",
    "        idf = idf_dict[word]\n",
    "        tf_idfs.append(tf*idf)\n",
    "    return tf_idfs\n",
    "\n",
    "def get_avg_word2vec(novel, word_2_vec):\n",
    "    vec_list = []\n",
    "    for word in novel:\n",
    "        if word in word2vec:\n",
    "            vec_list.append(word2vec[word])\n",
    "    vector_array = numpy.array(vec_list)\n",
    "    vector_array = numpy.mean(vector_array, axis=0)\n",
    "    return vector_array.tolist()\n",
    "\n",
    "def get_pairwise_similarity(sentences, word2vec):\n",
    "    sentence_vectors = []\n",
    "    for sentence in sentences:\n",
    "        vec_list = []\n",
    "        for word in sentence:\n",
    "            if word in word2vec:\n",
    "                vec_list.append(word2vec[word])\n",
    "        if len(vec_list) > 0:\n",
    "            vector_array = numpy.array(vec_list)\n",
    "            vector_array = numpy.mean(vector_array, axis=0)\n",
    "            sentence_vectors.append(vector_array)\n",
    "    cs_sim = cosine_similarity(sentence_vectors, sentence_vectors)\n",
    "    return numpy.mean(cs_sim)\n",
    "\n",
    "def get_pos_vector(novel, pos_tags):\n",
    "    tagged_tokens = nltk.pos_tag(novel)\n",
    "    tags = [tag for (word, tag) in tagged_tokens]\n",
    "    num_tokens = len(novel)\n",
    "    pos_vector = [tags.count(pos_tag) / num_tokens for pos_tag in pos_tags]\n",
    "    return pos_vector\n",
    "\n",
    "def feature_vector(novel, vocab, idf_dict, pos_tags, word_2_vec):\n",
    "    tokenized_novel = clean_and_tokenize_file(novel)\n",
    "    tokens = tokenized_novel[0]\n",
    "    sents = tokenized_novel[1]\n",
    "    unigram_vector = tf_idf(vocab, tokens, idf_dict)\n",
    "    pos_vector = get_pos_vector(tokens, pos_tags)\n",
    "    word_2_vec_vector = get_avg_word2vec(tokens, word_2_vec)\n",
    "    word_vector = unigram_vector + pos_vector + word_2_vec_vector\n",
    "    \n",
    "    # gets ratio of unique words to total # of words\n",
    "    novel_vocab = count_total_vocab([tokens])\n",
    "    vocab_size = len(novel_vocab) / len(tokens)\n",
    "    word_vector.append(vocab_size)\n",
    "    \n",
    "    cs_similarity = get_pairwise_similarity(sents, word_2_vec)\n",
    "    word_vector.append(cs_similarity)\n",
    "    \n",
    "    return word_vector\n",
    "\n",
    "\n",
    "def create_vector_arrays(training_data, corpus_dict, vocab, idf_dict, pos_tags, word_2_vec):\n",
    "    len_feature_vector = len(vocab) + len(pos_tags) + 102\n",
    "    print(len_feature_vector)\n",
    "    vector_array = numpy.zeros((len(training_data), len_feature_vector))\n",
    "    results_array = numpy.zeros(len(training_data))\n",
    "    index = 0\n",
    "    for data, age in training_data.items():\n",
    "        results_array[index] = age\n",
    "        vector_array[index] = feature_vector(corpus_dict + data, vocab, idf_dict, pos_tags, word_2_vec)\n",
    "        index += 1\n",
    "    return (vector_array, results_array)\n",
    "    \n",
    "    \n",
    "training_data = {'121-0.txt': 28, '158-0.txt':40}\n",
    "vocab = get_corpus_vocab(corpus, 200)\n",
    "idf_dict = get_idf_dict(vocab, corpus)\n",
    "corpus_dict = 'data/JaneAusten/'    \n",
    "\n",
    "tagset = ['CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNS', 'NNP', 'NNPS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB']\n",
    "\n",
    "create_vector_arrays(training_data, corpus_dict, vocab, idf_dict, tagset, word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from torch import tensor, Size\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch import functional\n",
    "from torch import from_numpy\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "input_array = array(features_vector_array[0], dtype='float32')\n",
    "input_vector = from_numpy(input_array)\n",
    "\n",
    "output_array = array(features_vector_array[1], dtype='float32')\n",
    "target_vector = from_numpy(output_array)\n",
    "\n",
    "input_and_target = TensorDataset(input_vector, target_vector)\n",
    "\n",
    "predict_array = array(test_vector, dtype='float32')\n",
    "predict_vector = from_numpy(predict_array)\n",
    "\n",
    "dickens_predict_array = array(dickens_test_array, dtype='float32')\n",
    "dickens_predict_vector = from_numpy(dickens_predict_array)\n",
    "\n",
    "linear_model = nn.Linear(115, 1)\n",
    "loss_func = nn.functional.mse_loss \n",
    "optimize = optim.SGD(linear_model.parameters(), lr=0.001)\n",
    "loss = loss_func(linear_model(input_vector), target_vector)\n",
    "\n",
    "def train(num_epochs, model, loss_func, optimizer):\n",
    "    for epoch in range(num_epochs):\n",
    "        for xb,yb in input_and_target:\n",
    "            \n",
    "            # Predictions\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "            \n",
    "            # Stochastic radient descent\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "    print(loss)\n",
    "\n",
    "train(500, linear_model, loss_func, optimize)\n",
    "\n",
    "pred = linear_model(predict_vector)\n",
    "print(pred)\n",
    "\n",
    "def goodness(predicted, actual, range_size):\n",
    "    return float((predicted - actual)) / float(range_size)\n",
    "\n",
    "print(\"Jane Austen\")\n",
    "print(\"Age predicted for Mansfield Park: %s\" % pred)\n",
    "print(\"Goodness Metric: %s\\n\" % abs(goodness(pred, 39, 15)))\n",
    "\n",
    "pred = linear_model(dickens_predict_vector)\n",
    "print(\"Charles Dickens\")\n",
    "print(\"Age predicted for Oliver Twist: %s\" % pred)\n",
    "print(\"Goodness Metric: %s\" % abs(goodness(pred, 25, 10)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
